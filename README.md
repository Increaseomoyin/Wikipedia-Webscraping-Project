# Wikipedia Webscraping Project

## Project Overview
This project aims to extract a table dataset from Wikipedia's website using specific packages in python such as BeautifulSoup and requests, 
and to also save this data as a file for easy readability and analysis using packages like pandas in python.

### Data Sources
Wikipedia website: The source is the [wikipedia's website](https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue)

### Tools

-Jupyter Notebook - Where all the codes were written

-BeautifulSoup and requests- For scraping the data from the website

-Pandas= for representing the data as a table and saving it as a file

### Data cleaning/Preparation

After I extracted the data from the internet, I performed small data cleaning on the "Employees" column 
using pandas 

### Results

I was able to combined my knowledge of various python packages to efficiently scrape and save data from the internet
as a csv file "Wikipedia_Webscrapping.csv", as contained in the repository

### References

-[Wikipedia](https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue)


